{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a first selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "\n",
    "\n",
    "# Impute null values\n",
    "\n",
    "\n",
    "# Create y\n",
    "# Load necessary packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "features = [col for col in df.columns if df[col].dtype in [np.float64, np.int64] and col!='SalePrice']\n",
    "X = df[features]\n",
    "\n",
    "# Impute null values\n",
    "for col in X:\n",
    "    med = X[col].median()\n",
    "    X[col].fillna(value = med, inplace = True)\n",
    "\n",
    "# Create y\n",
    "y = df.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1460 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8002792703767118\n",
      "Testing r^2: 0.8419604129830918\n",
      "Training MSE: 1276864534.0518208\n",
      "Testing MSE: 951354909.433369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# Split in train and test\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "#linear regression for xtrain and y train score\n",
    "print('Training r^2:', linreg.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg.score(X_test, y_test))\n",
    "#get the mean squared error of y train and the linear regression predict of xtrain\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# scale the data and perform train test split\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7987511627404219\n",
      "Testing r^2: 0.841777187574803\n",
      "Training MSE: 1285875639.5455616\n",
      "Testing MSE: 954600272.7646444\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "linreg_norm = LinearRegression()\n",
    "linreg_norm.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_norm.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_norm.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_norm.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_norm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't included dummy variables so far: let's use our \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "# Create X_cat which contains only the categorical variables\n",
    "features_cat = [col for col in df.columns if df[col].dtype in [np.object]]\n",
    "X_cat = df[features_cat]\n",
    "\n",
    "np.shape(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 252)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dummies\n",
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "np.shape(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_all = pd.concat([pd.DataFrame(X_scaled), X_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.9378350168099928\n",
      "Testing r^2: -4.86154676687089e+16\n",
      "Training MSE: 377416423.7379076\n",
      "Testing MSE: 3.407271789418969e+26\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y)\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far far off. Similarly, the scale of the Testing MSE is orders of magnitude higher then that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.9377942063217\n",
      "Testing r^2: 0.8743345274503859\n",
      "Training MSE: 377664192.6224483\n",
      "Testing MSE: 880741130.4569166\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso() \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.9366202378138652\n",
      "Testing r^2: 0.8821517812107345\n",
      "Training MSE: 384791597.36176413\n",
      "Testing MSE: 825952995.1460052\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=10) #Lasso is also known as the L1 norm.\n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.9240559879657525\n",
      "Testing r^2: 0.8816260757184347\n",
      "Training MSE: 461071747.39623636\n",
      "Testing MSE: 829637463.4425193\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "ridge = Ridge() #Lasso is also known as the L1 norm.\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Training r^2:', ridge.score(X_train, y_train))\n",
    "print('Testing r^2:', ridge.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8980811805414304\n",
      "Testing r^2: 0.8856473434337042\n",
      "Training MSE: 618770156.0872627\n",
      "Testing MSE: 801453939.348277\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 10) #Lasso is also known as the L1 norm.\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Training r^2:', ridge.score(X_train, y_train))\n",
    "print('Testing r^2:', ridge.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -172.8131268 ,  -5152.65676822,  -2946.12721339,   4490.68455693,\n",
       "        14988.98877711,   5114.66550093,   3039.00691734,   1545.56979317,\n",
       "         2048.53935029,    642.70591032,   1008.29842454,    184.7482657 ,\n",
       "         1225.03427924,   5416.07277993,  10887.22176555,    817.2813523 ,\n",
       "        13104.4053565 ,   3241.48900316,   -444.28194048,   3653.75786914,\n",
       "         2625.37056317,  -1718.12278431,  -2834.65716119,   5846.84218744,\n",
       "         2993.96310616,  -2019.01732277,   9690.93794638,    259.59747463,\n",
       "         2222.80220149,   -523.7244643 ,    881.00479674,   1845.50815524,\n",
       "         1907.96316621,   1458.80238408,   -898.65450185,    275.79743806,\n",
       "         -645.55506881,  -7802.62442741,   8510.92145356,   2024.54255522,\n",
       "         2268.29661558,  -5001.13619695,  -6620.3010912 ,   6620.3010912 ,\n",
       "         -693.57245245,  -2039.66705584,   3209.74866886,   7628.01629652,\n",
       "       -12150.65491603,   1312.88995064, -12627.00604274,   6555.62803258,\n",
       "         -398.31196795,   6469.68997811,   2729.55882418,  -2729.55882418,\n",
       "         1437.84314101,   8626.6910553 ,  -6010.04996079,  -4452.70320758,\n",
       "          398.21897206,  -1779.08288646,  10006.71147667,  -8227.62859021,\n",
       "        -7213.09462939,   -831.10877425,   1619.73409361,   4251.74424987,\n",
       "        -3952.02402349,  -5624.12048358,  11762.06761132, -14121.05499984,\n",
       "        -8079.24567804,  -3731.79417623,  -1752.1970595 , -12903.54781607,\n",
       "        -8675.54243693,    409.65958584,  -9458.13251357,  29108.59506662,\n",
       "        21785.80222637,  -8393.50288146,  -2454.48504995,  -3904.75383538,\n",
       "        -1381.264042  ,   5509.26127808,  19710.91270473,  -4394.25184688,\n",
       "         2712.34343011,   1359.41490298,  -2986.17927228,  10075.84436792,\n",
       "         1337.0054443 ,  -5088.57264458,  -7886.3917823 ,   4398.54918783,\n",
       "        -1180.38437159,    -29.28583228,   1547.17151264,   1399.82860074,\n",
       "        11578.39865634,   4014.02988223, -21198.67380501,      0.        ,\n",
       "          602.17596547,   2057.06918759,   2360.9170912 ,   8088.99911778,\n",
       "          616.23519466,  -7652.40249384,  -3413.74890981,  -2915.24175667,\n",
       "        -1472.8213542 ,   9129.0961376 ,    134.0378596 ,  -1286.56406034,\n",
       "        -8276.29861492,   2054.69694754,   2633.09484138,    646.08131085,\n",
       "        -1994.73541685,  -1504.64053286,   1057.10834114,   1796.18629772,\n",
       "            0.        , -26604.20210359,  11313.08614804,      0.        ,\n",
       "            0.        ,      0.        ,   -807.55923864,   1216.65074148,\n",
       "        14882.02445271,  -2455.19830797,      0.        ,   -240.35408162,\n",
       "        12187.64224675,     46.27275388,   -497.86952092,  -3498.71866692,\n",
       "            0.        ,    765.61667336,  -1879.64790651,    859.05668211,\n",
       "        -9381.54711326,   2716.74760771,   -375.03975527,   1753.03938867,\n",
       "        -3646.97256939,   2271.08336275,   -135.61102373,   2978.96255215,\n",
       "           46.27275388,   3659.85555183,    592.64610638,  14117.19525433,\n",
       "         -210.26195605,    385.15901327,  -1060.99363421,  -4194.82389273,\n",
       "        -9103.13903674,   1980.51147748,   -645.04875397,  -7034.83520523,\n",
       "        -5097.28523608,   -910.2647463 ,   3489.25420873,   1012.09260076,\n",
       "         5734.26877295,   -527.31487383,    -66.31236484,  -5140.64153428,\n",
       "         3044.71355897,   3225.34693025,  -2592.60750165,  -1210.79744416,\n",
       "        -2466.65554341,     99.72652583,   5121.82035646,   3265.79849316,\n",
       "        -3392.16084541,    606.1113246 ,  -5701.29585464,  20518.46997562,\n",
       "         1719.00130651,  -7888.43329783,  -6760.17035783,    566.49045032,\n",
       "         1043.07027746,   1745.55880576,   4233.74809294,   -490.91417404,\n",
       "        14208.2845511 ,   1259.51672977,  -6158.31822497,   1767.49144613,\n",
       "         3105.71980279,   9258.08801505,  -3152.57139412,    495.36869887,\n",
       "        -3885.22894225,   5972.67659157,   -708.627277  ,   -921.36430817,\n",
       "         -478.12179294,   -272.97164832,   2848.99588933,  -1116.05697861,\n",
       "         -535.55891971,   3316.65452605,    660.3442546 ,  -2674.37467642,\n",
       "          348.9917941 ,   1189.16524582,   2953.54581568,  -2136.70497885,\n",
       "        -1326.01973136,   -679.98635128,    -47.89161827,     47.89161827,\n",
       "        -1187.6915513 ,   -855.03360798,   2145.88149569,      0.        ,\n",
       "        -1515.07716882,  17987.16160497,  -3383.05973873,  -7434.89228819,\n",
       "        -7169.20957805,  -5181.97893533,  -1292.45932525,   1125.33565973,\n",
       "          743.3173515 ,  -2023.13612935,  -3006.70767661,   9635.62905531,\n",
       "         3090.99147272,  -1912.43794122,  -2194.26613274,   -890.30013857,\n",
       "         1051.95362378,  -5227.87534288,  -1379.12269544,   1094.48593284,\n",
       "        -3462.00872453,  -1179.30094185,    383.00336732,  -1598.98216864,\n",
       "        -4551.86961406,  -3619.96662184,   6470.7213098 , -10249.12870425,\n",
       "         4235.46748414,  -1566.66085214,  -8661.21764209,   -565.87987203,\n",
       "        -5451.21956129,   -672.62816392,  -3519.30013119,    438.20932389,\n",
       "        -3621.29978385,   -222.02138732,   3843.32117118,  20056.24110618,\n",
       "        -3862.65496204, -21469.72985335,  -1772.16120822,    346.66009686,\n",
       "         1746.61305536,  -1163.96586776,      0.        ,    266.70870887,\n",
       "        -1722.02953671,  -3187.2384966 ,  -9437.32748898,   2360.69748723,\n",
       "         2281.26778794,   3850.3331665 ,   4264.43867846,  -2667.77766432,\n",
       "         3287.25046289,   3525.50048852,  -7464.38291823,  -3383.78213987,\n",
       "         1048.14380371,   3171.16923105,  -5619.35263577,   4508.94884658,\n",
       "          274.8728943 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# number of Ridge params almost zero\n",
    "print(sum(abs(ridge.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "# number of Lasso params almost zero\n",
    "print(sum(abs(lasso.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "len(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25259515570934254"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(lasso.coef_) < 10**(-10))/289"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
